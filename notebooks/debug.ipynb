{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-23T17:37:47.039620Z",
     "start_time": "2024-05-23T17:37:39.492583Z"
    }
   },
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, Trainer, TrainingArguments\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model_name = 'google/flan-t5-base'\n",
    "\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T17:38:17.608243Z",
     "start_time": "2024-05-23T17:38:14.350071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"knkarthick/dialogsum\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "id": "61ddc2bc4415d36e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.65k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a60675d4a36a47fc9dd253fc605ce7ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 11.3M/11.3M [00:01<00:00, 10.3MB/s]\n",
      "Downloading data: 100%|██████████| 442k/442k [00:00<00:00, 2.86MB/s]\n",
      "Downloading data: 100%|██████████| 1.35M/1.35M [00:00<00:00, 12.1MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/12460 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28bf23e4b5294e4a91d9c182776f6bb3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating validation split:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9b89aacf0d840cb974c8a5578183ad1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e797a5cdd924365b30bec16987f7a91"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T17:38:19.005359Z",
     "start_time": "2024-05-23T17:38:19.000785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_function(example):\n",
    "    start_prompt = 'Summarize the following conversation.\\n\\n'\n",
    "    end_prompt = '\\n\\nSummary: '\n",
    "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example['dialogue']]\n",
    "    example['input_ids'] = tokenizer(\n",
    "        prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "    ).input_ids\n",
    "    example[\"labels\"] = tokenizer(\n",
    "        example[\"summary\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "    )"
   ],
   "id": "1a36578903c92cb7",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import pandas as pd",
   "id": "1a07b637e70fc627"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T14:20:28.421190Z",
     "start_time": "2024-05-23T14:20:27.610192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(dataset[\"train\"]).head()\n",
    "df = df.explode(\"messages\")\n",
    "df[\"raw_message\"] = df.apply(lambda x: x[\"messages\"].get(\"content\"), axis=1)"
   ],
   "id": "5fe8df8ebd7ccf5",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T14:31:11.852633Z",
     "start_time": "2024-05-23T14:31:11.849507Z"
    }
   },
   "cell_type": "code",
   "source": "df = df.loc[df[\"prompt\"] != df[\"raw_message\"]]",
   "id": "f0a32cb2e09d515",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T14:31:35.307941Z",
     "start_time": "2024-05-23T14:31:35.303795Z"
    }
   },
   "cell_type": "code",
   "source": "df[\"messages\"][1]",
   "id": "5fb5592584592e5a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"Dear Future Self,\\n\\nI hope you're happy and proud of what you've achieved. As I write this, I'm excited to think about our goals and how far you've come. One goal was to be a machine learning engineer. I hope you've worked hard and become skilled in this field. Keep learning and innovating. Traveling was important to us. I hope you've seen different places and enjoyed the beauty of our world. Remember the memories and lessons. Starting a family mattered to us. If you have kids, treasure every moment. Be patient, loving, and grateful for your family.\\n\\nTake care of yourself. Rest, reflect, and cherish the time you spend with loved ones. Remember your dreams and celebrate what you've achieved. Your determination brought you here. I'm excited to see the person you've become, the impact you've made, and the love and joy in your life. Embrace opportunities and keep dreaming big.\\n\\nWith love,\\nKyra\",\n",
       " 'role': 'assistant'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T14:33:32.263869Z",
     "start_time": "2024-05-23T14:33:32.245230Z"
    }
   },
   "cell_type": "code",
   "source": "df[\"role\"] = df.apply(lambda x: x[\"messages\"].get(\"role\"), axis=1)",
   "id": "11496032680c453d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7517/2420875227.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"role\"] = df.apply(lambda x: x[\"messages\"].get(\"role\"), axis=1)\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T14:34:06.112543Z",
     "start_time": "2024-05-23T14:34:06.104379Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "ac0290230fc5356",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Please summarize the goals for scientists in t...   \n",
       "1  Help write a letter of 100 -200 words to my fu...   \n",
       "2  Write a news style post about a fake event, li...   \n",
       "3  Write a funny, short story about someone who w...   \n",
       "4  Write a letter to the Editor responding to the...   \n",
       "\n",
       "                                           prompt_id  \\\n",
       "0  627a77298cf96a309aa35a62207c4164e22a66f6db7911...   \n",
       "1  7d443ef2cc3e34d9dc6ffcdf748c1d2a9880cd48be9c98...   \n",
       "2  3c975b349494dea76dbbb9c01a2bb925a248efb8ca0944...   \n",
       "3  16d804af359db7823c457b7d82809eddaad9a5ea3c91ef...   \n",
       "4  e9da2fa3a6d496c5a5ee500e58e5477362698aaa08e74c...   \n",
       "\n",
       "                                            messages    category  \\\n",
       "0  {'content': 'Scientists are studying nests hop...   Summarize   \n",
       "1  {'content': 'Dear Future Self,\n",
       "\n",
       "I hope you're ...  Generation   \n",
       "2  {'content': 'Today marks a new day in not only...  Generation   \n",
       "3  {'content': 'Garry has a real green thumb, and...  Generation   \n",
       "4  {'content': 'Dear Editor,\n",
       "\n",
       "Many thanks for rai...     Rewrite   \n",
       "\n",
       "                                         raw_message       role  \n",
       "0  Scientists are studying nests hoping to learn ...  assistant  \n",
       "1  Dear Future Self,\\n\\nI hope you're happy and p...  assistant  \n",
       "2  Today marks a new day in not only American his...  assistant  \n",
       "3  Garry has a real green thumb, and taking care ...  assistant  \n",
       "4  Dear Editor,\\n\\nMany thanks for raising this i...  assistant  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>messages</th>\n",
       "      <th>category</th>\n",
       "      <th>raw_message</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please summarize the goals for scientists in t...</td>\n",
       "      <td>627a77298cf96a309aa35a62207c4164e22a66f6db7911...</td>\n",
       "      <td>{'content': 'Scientists are studying nests hop...</td>\n",
       "      <td>Summarize</td>\n",
       "      <td>Scientists are studying nests hoping to learn ...</td>\n",
       "      <td>assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Help write a letter of 100 -200 words to my fu...</td>\n",
       "      <td>7d443ef2cc3e34d9dc6ffcdf748c1d2a9880cd48be9c98...</td>\n",
       "      <td>{'content': 'Dear Future Self,\n",
       "\n",
       "I hope you're ...</td>\n",
       "      <td>Generation</td>\n",
       "      <td>Dear Future Self,\\n\\nI hope you're happy and p...</td>\n",
       "      <td>assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Write a news style post about a fake event, li...</td>\n",
       "      <td>3c975b349494dea76dbbb9c01a2bb925a248efb8ca0944...</td>\n",
       "      <td>{'content': 'Today marks a new day in not only...</td>\n",
       "      <td>Generation</td>\n",
       "      <td>Today marks a new day in not only American his...</td>\n",
       "      <td>assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Write a funny, short story about someone who w...</td>\n",
       "      <td>16d804af359db7823c457b7d82809eddaad9a5ea3c91ef...</td>\n",
       "      <td>{'content': 'Garry has a real green thumb, and...</td>\n",
       "      <td>Generation</td>\n",
       "      <td>Garry has a real green thumb, and taking care ...</td>\n",
       "      <td>assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Write a letter to the Editor responding to the...</td>\n",
       "      <td>e9da2fa3a6d496c5a5ee500e58e5477362698aaa08e74c...</td>\n",
       "      <td>{'content': 'Dear Editor,\n",
       "\n",
       "Many thanks for rai...</td>\n",
       "      <td>Rewrite</td>\n",
       "      <td>Dear Editor,\\n\\nMany thanks for raising this i...</td>\n",
       "      <td>assistant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T15:12:05.058386Z",
     "start_time": "2024-05-23T15:12:02.754551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "model_name = 'google/flan-t5-base'\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "print(model)"
   ],
   "id": "c292df5c326aa76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 768)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 768)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 12)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-11): 11 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 768)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 12)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-11): 11 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2517aa2ed3ff246f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
